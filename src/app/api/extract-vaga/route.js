import { createClient } from '@supabase/supabase-js'
import axios from 'axios'
import * as cheerio from 'cheerio'

// Criar cliente admin com service role
const supabaseAdmin = createClient(
  process.env.NEXT_PUBLIC_SUPABASE_URL,
  process.env.SUPABASE_SERVICE_ROLE_KEY,
  {
    auth: {
      autoRefreshToken: false,
      persistSession: false
    }
  }
)

class JobScraper {
  constructor() {
    this.axiosConfig = {
      timeout: 15000,
      headers: {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
        'Accept-Language': 'pt-BR,pt;q=0.9,en;q=0.8',
        'Accept-Encoding': 'gzip, deflate, br',
        'Connection': 'keep-alive',
        'Upgrade-Insecure-Requests': '1'
      }
    }
  }

  // Fun√ß√£o para limpar e normalizar texto
  cleanText(text) {
    if (!text) return ''
    return text
      .replace(/\s+/g, ' ') // M√∫ltiplos espa√ßos em um
      .replace(/\n+/g, '\n') // M√∫ltiplas quebras de linha em uma
      .replace(/\t+/g, ' ') // Tabs em espa√ßos
      .trim()
  }

  // Fun√ß√£o para extrair se√ß√µes espec√≠ficas do HTML
  extractSection($, selector, fallbackPatterns = []) {
    // Tentar primeiro com seletor CSS
    let content = $(selector).text()
    if (content && content.trim()) {
      return this.cleanText(content)
    }

    // Tentar com padr√µes de regex
    const fullText = $('body').text()
    for (const pattern of fallbackPatterns) {
      const regex = new RegExp(pattern, 'is')
      const match = fullText.match(regex)
      if (match && match[1]) {
        return this.cleanText(match[1])
      }
    }
    return ''
  }

  // Extrair informa√ß√µes espec√≠ficas do Gupy
  extractGupyInfo($) {
    const jobData = {
      url: '',
      titulo: '',
      descricao: '',
      responsabilidades: '',
      requisitos: '',
      salario: '',
      horario_trabalho: '',
      jornada_trabalho: '',
      beneficios: '',
      local_trabalho: '',
      etapas_processo: '',
      data_extracao: new Date().toISOString()
    }

    // Extrair t√≠tulo - tentar m√∫ltiplos seletores
    const titleSelectors = [
      'h1[data-testid="job-title"]',
      'h1.job-title',
      'h1',
      '[data-testid="job-title"]',
      '.job-title'
    ]
    
    for (const selector of titleSelectors) {
      const title = $(selector).first().text().trim()
      if (title) {
        jobData.titulo = this.cleanText(title)
        break
      }
    }

    // Extrair descri√ß√£o da vaga
    jobData.descricao = this.extractSection($, 
      '[data-testid="job-description"], .job-description, .description',
      [
        'Descri√ß√£o da vaga[:\\s]*([\\s\\S]*?)(?=Responsabilidades|Requisitos|Benef√≠cios|Etapas|Informa√ß√µes|$)',
        'Sobre a vaga[:\\s]*([\\s\\S]*?)(?=Responsabilidades|Requisitos|Benef√≠cios|Etapas|Informa√ß√µes|$)'
      ]
    )

    // Extrair responsabilidades
    jobData.responsabilidades = this.extractSection($,
      '[data-testid="job-responsibilities"], .responsibilities, .responsabilidades',
      [
        'Responsabilidades e atribui√ß√µes[:\\s]*([\\s\\S]*?)(?=Requisitos|Qualifica√ß√µes|Benef√≠cios|Etapas|Informa√ß√µes|$)',
        'Responsabilidades[:\\s]*([\\s\\S]*?)(?=Requisitos|Qualifica√ß√µes|Benef√≠cios|Etapas|Informa√ß√µes|$)',
        'Atribui√ß√µes[:\\s]*([\\s\\S]*?)(?=Requisitos|Qualifica√ß√µes|Benef√≠cios|Etapas|Informa√ß√µes|$)'
      ]
    )

    // Extrair requisitos
    jobData.requisitos = this.extractSection($,
      '[data-testid="job-requirements"], .requirements, .requisitos',
      [
        'Requisitos e qualifica√ß√µes[:\\s]*([\\s\\S]*?)(?=Benef√≠cios|Informa√ß√µes|Etapas|Local|Hor√°rio|$)',
        'Requisitos[:\\s]*([\\s\\S]*?)(?=Benef√≠cios|Informa√ß√µes|Etapas|Local|Hor√°rio|$)',
        'Qualifica√ß√µes[:\\s]*([\\s\\S]*?)(?=Benef√≠cios|Informa√ß√µes|Etapas|Local|Hor√°rio|$)'
      ]
    )

    // Extrair sal√°rio - procurar em m√∫ltiplos lugares
    const salarySelectors = [
      '[data-testid="salary"], .salary, .salario',
      'text:contains("Sal√°rio")',
      'text:contains("Remunera√ß√£o")'
    ]
    
    for (const selector of salarySelectors) {
      const salaryText = $(selector).text()
      if (salaryText && (salaryText.includes('R$') || salaryText.includes('sal√°rio'))) {
        const salaryMatch = salaryText.match(/R\$\s*[\d.,]+/g)
        if (salaryMatch) {
          jobData.salario = salaryMatch[0]
          break
        }
      }
    }

    // Se n√£o encontrou sal√°rio, tentar com regex no texto completo
    if (!jobData.salario) {
      const fullText = $('body').text()
      const salaryPatterns = [
        /Sal√°rio[:\\s]*R\$\s*[\d.,]+/gi,
        /Remunera√ß√£o[:\\s]*R\$\s*[\d.,]+/gi,
        /R\$\s*[\d.,]+/g
      ]
      
      for (const pattern of salaryPatterns) {
        const match = fullText.match(pattern)
        if (match) {
          jobData.salario = match[0].trim()
          break
        }
      }
    }

    // Extrair hor√°rio de trabalho
    jobData.horario_trabalho = this.extractSection($,
      '[data-testid="work-schedule"], .work-schedule, .horario',
      [
        'Hor√°rio de Trabalho[:\\s]*([^\\n]*?)(?=Jornada|Benef√≠cios|Local|Etapas|$)',
        'Hor√°rio[:\\s]*([^\\n]*?)(?=Jornada|Benef√≠cios|Local|Etapas|$)'
      ]
    )

    // Extrair jornada de trabalho
    jobData.jornada_trabalho = this.extractSection($,
      '[data-testid="work-hours"], .work-hours, .jornada',
      [
        'Jornada de Trabalho[:\\s]*([^\\n]*?)(?=Benef√≠cios|Local|Etapas|$)',
        'Jornada[:\\s]*([^\\n]*?)(?=Benef√≠cios|Local|Etapas|$)'
      ]
    )

    // Extrair benef√≠cios
    jobData.beneficios = this.extractSection($,
      '[data-testid="benefits"], .benefits, .beneficios',
      [
        'Benef√≠cios[:\\s]*([\\s\\S]*?)(?=Local|Etapas|Processo|$)',
        'O que oferecemos[:\\s]*([\\s\\S]*?)(?=Local|Etapas|Processo|$)'
      ]
    )

    // Extrair local de trabalho
    jobData.local_trabalho = this.extractSection($,
      '[data-testid="work-location"], .work-location, .local',
      [
        'Local de Trabalho[:\\s]*([^\\n]*?)(?=Etapas|Processo|$)',
        'Local[:\\s]*([^\\n]*?)(?=Etapas|Processo|$)'
      ]
    )

    // Extrair etapas do processo
    jobData.etapas_processo = this.extractSection($,
      '[data-testid="process-steps"], .process-steps, .etapas',
      [
        'Etapas do processo[:\\s]*([\\s\\S]*?)(?=Muito prazer|Somos|$)',
        'Processo seletivo[:\\s]*([\\s\\S]*?)(?=Muito prazer|Somos|$)'
      ]
    )

    return jobData
  }

  async extractJobInfo(url) {
    try {
      console.log(`üîç Extraindo informa√ß√µes de: ${url}`)
      
      const response = await axios.get(url, this.axiosConfig)
      const $ = cheerio.load(response.data)
      
      // Extrair informa√ß√µes espec√≠ficas do Gupy
      const jobData = this.extractGupyInfo($)

      // Definir URL
      jobData.url = url

      // Se n√£o conseguiu extrair t√≠tulo, tentar do title da p√°gina
      if (!jobData.titulo) {
        jobData.titulo = $('title').text().trim() || 'T√≠tulo n√£o encontrado'
      }

      // Limpar e normalizar todos os campos
      Object.keys(jobData).forEach(key => {
        if (typeof jobData[key] === 'string') {
          jobData[key] = this.cleanText(jobData[key])
        }
      })

      console.log(`‚úÖ Extra√ß√£o conclu√≠da: ${jobData.titulo}`)
      return jobData

    } catch (error) {
      console.error('‚ùå Erro na extra√ß√£o:', error.message)
      throw new Error(`Erro ao extrair informa√ß√µes: ${error.message}`)
    }
  }
}

export async function POST(request) {
  try {
    console.log('=== EXTRA√á√ÉO DE VAGA ===')
    
    // Verificar se o cliente Supabase est√° configurado
    if (!supabaseAdmin) {
      console.error('‚ùå Cliente Supabase n√£o foi criado')
      return Response.json({ 
        error: 'Cliente Supabase n√£o configurado' 
      }, { status: 500 })
    }

    const { url } = await request.json()
    
    if (!url) {
      return Response.json({ 
        error: 'URL √© obrigat√≥ria' 
      }, { status: 400 })
    }
    
    if (!url.includes('gupy.io')) {
      return Response.json({ 
        error: 'URL deve ser do Gupy' 
      }, { status: 400 })
    }
    
    const scraper = new JobScraper()
    const jobData = await scraper.extractJobInfo(url)
    
    return Response.json({
      success: true,
      data: jobData
    })
    
  } catch (error) {
    console.error('Erro na extra√ß√£o:', error)
    return Response.json({ 
      error: error.message 
    }, { status: 500 })
  }
}